{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import emoji\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopee_dataset = pd.read_csv(\"shopee_reviews.csv\")\n",
    "ebay_dataset = pd.read_csv(\"ebay_reviews.csv\", usecols=['review title', 'review content'])\n",
    "amazon_dataset = pd.read_csv(\"Reviews.csv\", usecols=['ProductId', 'UserId', 'Time', 'Text'])\n",
    "walmart_dataset = pd.read_csv(\"marketing_sample_for_walmart_com-walmart_product_reviews__20200401_20200630__30k_data.csv\", usecols=['Review', 'Reviewer Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up methods for getting polarity, subjectivity, and analyzing polarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subjectivity score of text\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Get polarity score of text\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Analyze polarity score\n",
    "def getAnalysis(polarity_score):\n",
    "    if polarity_score < 0:\n",
    "        return 'Negative'\n",
    "    elif polarity_score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text pre-processing\n",
    "\n",
    "Used pre-processing techniques:\n",
    "\n",
    " - Converting all characters to lowercase\n",
    " - Removing URLs\n",
    " - Removing hashtags\n",
    " - Removing numerical data\n",
    " - Converting emojis to words\n",
    " - Removing extra whitespaces\n",
    " - Correcting spelling\n",
    " - Removing stopwords\n",
    " - Tokenization\n",
    " - Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all characters to lowercase\n",
    "def lowercasing(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Remove URLs\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "# Remove hashtags\n",
    "def remove_hashtags(text):\n",
    "    hashtag_pattern = re.compile(r'#([^\\s]+)')\n",
    "    return hashtag_pattern.sub(r'', text)\n",
    "\n",
    "# Remove numerical data\n",
    "def remove_num(text):\n",
    "    return \"\".join([i for i in text if not i.isdigit()])\n",
    "\n",
    "# Emojis to words\n",
    "def emojiToWord(text):\n",
    "    demoji = emoji.demojize(text, delimiters=(\"__\", \"__\"))\n",
    "    demoji = demoji.replace('__', ' ')\n",
    "    demoji = demoji.replace('_', ' ')\n",
    "    return demoji\n",
    "\n",
    "# Remove extra whitespace\n",
    "def remove_extraws(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "# Spell checker\n",
    "spell = SpellChecker()\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_sw(text):\n",
    "    filtered_text = []\n",
    "    for w in text:\n",
    "        if w not in stop_words:\n",
    "            filtered_text.append(w)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing datasets \n",
    "# [code here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('datasci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "837c7ec606491fd0ef912280fc018ebdca83572edbf1796028bb3afef46af57e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
